{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Recommender - Project\n",
    "Mat.-Nr: 6574933\n",
    "\n",
    "Some more insights/backgrounds are in the project documentation."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First things first: some imports :D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras import layers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tabulate import tabulate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recommender System"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import 100k-Movielens Data\n",
    "The data is in csv files. To read and store them pandas got the method pd.read_csv()!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_data = pd.read_csv('Data/ml-100k/u.data', sep='\\t', names=[\"userID\", \"movieID\", \"rating\", \"timestamp\"])\n",
    "\n",
    "user_data = pd.read_csv('Data/ml-100k/u.user', sep='|', names=[\"userID\", \"age\", \"gender\",  \"occupation\", \"zip code\"])\n",
    "\n",
    "movies = pd.read_csv('Data/ml-100k/u.item', sep='|', encoding='latin-1', names=[\"movieID\", \"title\", \"release date\", \"video release date\", \"IMDb URL\", \"unknown\", \"Action\", \"Adventure\", \"Animation\", \"Children's\", \"Comedy\", \"Crime\", \"Documentary\", \"Drama\", \"Fantasy\", \"Film-Noir\", \"Horror\", \"Musical\", \"Mystery\", \"Romance\", \"Sci-Fi\", \"Thriller\", \"War\", \"Western\"])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So let`s start easy an look what the different dataframes look like :)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"###\"*20)\n",
    "print(\"Number of users: {}\\nNumber of movies: {}\\nNumber of given ratings: {}\".format(len(user_data), len(movies), len(rating_data)))\n",
    "\n",
    "print(\"\\n\" + \"###\"*20 + \"\\n\")\n",
    "\n",
    "print(\"User Data:\")\n",
    "print(user_data.head())\n",
    "\n",
    "print(\"\\n\" + \"###\"*20 + \"\\n\")\n",
    "\n",
    "print(\"Rating Data:\")\n",
    "print(rating_data.head())\n",
    "print(\"###\"*20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's analyse the users a bit more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gender_counts = user_data['gender'].value_counts()\n",
    "plt.pie(gender_counts, labels=gender_counts.index ,colors=['dodgerblue', 'pink'], labeldistance=0.6, startangle=90)\n",
    "plt.title(\"Gender Distribution\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "age_counts = user_data['age'].value_counts(bins=5).sort_index()\n",
    "age_labels = [str(x) for x in age_counts.index]\n",
    "plt.bar(age_labels, age_counts)\n",
    "plt.xlabel(\"Age Groups\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Age Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Male, Female = [], []\n",
    "\n",
    "for x in age_counts.index:\n",
    "    temp_user = user_data[user_data.age.between(x.left, x.right)]\n",
    "    gender_counts = temp_user['gender'].value_counts()\n",
    "    Male.append(gender_counts[0])\n",
    "    Female.append(gender_counts[1])\n",
    "\n",
    "X_axis = np.arange(len(age_labels))\n",
    "\n",
    "plt.bar(X_axis - 0.2, Female, 0.4, label = 'Female', color = 'pink')\n",
    "plt.bar(X_axis + 0.2, Male, 0.4, label = 'Male', color = 'dodgerblue')\n",
    "  \n",
    "plt.xticks(X_axis, age_labels)\n",
    "plt.xlabel(\"Age Groups\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Genders in each age group\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "occupation_counts = user_data['occupation'].value_counts().sort_values(ascending=True)\n",
    "plt.barh(occupation_counts.index, occupation_counts)\n",
    "plt.xlabel(\"Count\")\n",
    "plt.ylabel(\"Occupations\")\n",
    "plt.title(\"Occupation Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go on with some Movie Analysis..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pop_df = rating_data.groupby('movieID').count()['rating'].reset_index(name='count').sort_values('count', ascending=False)\n",
    "movies = pd.merge(movies, pop_df, on=\"movieID\")\n",
    "most_watched_movies = movies.nlargest(10,'count').sort_values(by='count')\n",
    "plt.barh(most_watched_movies[\"title\"], most_watched_movies[\"count\"])\n",
    "plt.xlabel(\"Count\")\n",
    "plt.ylabel(\"Movies\")\n",
    "plt.title(\"Most watched movies\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_df_agg = rating_data.groupby('movieID').agg(avg_rating=('rating', 'mean')).reset_index()\n",
    "rating_df_agg['avg_rating'] = np.round(rating_df_agg['avg_rating'], 2)\n",
    "\n",
    "rating_df_agg = pd.merge(rating_df_agg, movies, on='movieID', how='inner')\n",
    "rating_df_agg = rating_df_agg[rating_df_agg['count']>10]\n",
    "most_popular_movies = rating_df_agg.nlargest(10,'avg_rating').sort_values(by='avg_rating')\n",
    "plt.barh(most_popular_movies[\"title\"], most_popular_movies[\"avg_rating\"])\n",
    "plt.xlabel(\"Average Rating\")\n",
    "plt.ylabel(\"Movies\")\n",
    "plt.title(\"Best rated movies\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Genres\n",
    "movies_genre_name = np.array(pd.read_csv('Data/ml-100k/u.genre', sep='|', header=None, engine='python', encoding='latin-1').loc[:, 0])\n",
    "movies_genre = {}\n",
    "for x in movies_genre_name:\n",
    "    movies_genre [x] = movies[x].value_counts()[1]\n",
    "print(\"Note: One movie can have multiple genres!\")\n",
    "plt.barh(movies_genre_name, movies_genre.values())\n",
    "plt.xlabel(\"Count\")\n",
    "plt.ylabel(\"Genres\")\n",
    "plt.title(\"Genre Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And last but most important: Let's have a deeper look into the Rating data (the real data)! This is the data our model will learn and predict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_counts = rating_data[\"rating\"].value_counts().sort_index()\n",
    "plt.bar(rating_counts.index, rating_counts)\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Rating Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "given_ratings_per_user = rating_data[\"userID\"].value_counts()\n",
    "plt.hist(given_ratings_per_user, 8)\n",
    "plt.xlabel(\"Rated movies\")\n",
    "plt.ylabel(\"Number of users\")\n",
    "plt.title(\"Given ratings per user\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#value counts of movie Toy story\n",
    "rating_toy_story = rating_data.loc[rating_data[\"movieID\"]==int(movies[movies[\"title\"]=='Toy Story (1995)']['movieID'])]['rating'].value_counts()\n",
    "plt.bar(rating_toy_story.index, rating_toy_story)\n",
    "plt.xlabel(\"Rating\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.title(\"Ratings for Moive 'Toy Story (1995)'\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's again go back to the genders and have a look at the mean rating for some movies of different genres!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_df = pd.merge(rating_data, user_data, how='left', on = 'userID')\n",
    "full_df = pd.merge(full_df, movies, how='left', on = 'movieID')\n",
    "\n",
    "def print_gender_movie_rating(genre_movie_list, genre: str):\n",
    "    print('Genre: {}'.format(genre))\n",
    "    table_data = []\n",
    "    for i_movie in genre_movie_list:\n",
    "        temp_df = full_df[full_df['title']==i_movie]\n",
    "        table_data.append([i_movie, temp_df[temp_df['gender']=='M']['rating'].mean(),  temp_df[temp_df['gender']=='F']['rating'].mean()])\n",
    "    temp_df = full_df[full_df[genre]==1]\n",
    "    table_data.append([\"Overall\", temp_df[temp_df['gender']=='M']['rating'].mean(),  temp_df[temp_df['gender']=='F']['rating'].mean()])\n",
    "    print(tabulate(table_data, headers=['Movie Titles', 'Male Mean Rating', \"Female Mean Rating\"], tablefmt='orgtbl'))\n",
    "    print('---'*8 + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drama\n",
    "drama_movies = ['Taxi Driver (1976)', 'Godfather, The (1972)', \"Schindler's List (1993)\"]\n",
    "print_gender_movie_rating(drama_movies, 'Drama')\n",
    "\n",
    "# Romance\n",
    "romance_movies = [\"Titanic (1997)\", \"Everyone Says I Love You (1996)\", \"Wedding Singer, The (1998)\"]\n",
    "print_gender_movie_rating(romance_movies, 'Romance')\n",
    "\n",
    "# Horror\n",
    "horror_movies = [\"Scream (1996)\", \"Stephen King's The Langoliers (1995)\", \"Halloween: The Curse of Michael Myers (1995)\"]\n",
    "print_gender_movie_rating(horror_movies, 'Horror')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop user data I will not use\n",
    "user_data = user_data.drop(columns=['zip code'])\n",
    "\n",
    "# Gender: Convert 'M' and 'F' to 0 and 1\n",
    "user_data['gender'] = np.where(np.matrix(user_data['gender']) == 'M', 0, 1)[0]\n",
    "\n",
    "# Occupation: Convert strings to int --> Network can handle it\n",
    "occupation_list = {\"none\": 0,  \"other\": 1, \"student\": 2, \"homemaker\": 3, \"artist\": 4, \"writer\": 5, \"entertainment\": 6, \"administrator\": 7, \"educator\": 8, \"librarian\": 9,\n",
    "                   \"lawyer\": 10, \"healthcare\": 11, \"doctor\": 12, \"scientist\": 13, \"engineer\": 14, \"technician\": 15, \"programmer\": 16, \"marketing\": 17, \"salesman\": 18, \n",
    "                   \"executive\": 19, \"retired\": 20\n",
    "                }\n",
    "user_data['occupation'] = user_data['occupation'].map(occupation_list)\n",
    "\n",
    "# Drop some movie data I will not use\n",
    "movie_data = movies.drop(columns=[\"title\", \"release date\", \"IMDb URL\", \"video release date\", \"count\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in predefined training and test set from the data\n",
    "training = pd.read_csv('Data/ml-100k/u1.base', sep='\\t', names=[\"userID\", \"movieID\", \"rating\", \"timestamp\"])\n",
    "test = pd.read_csv('Data/ml-100k/u1.test', sep='\\t', names=[\"userID\", \"movieID\", \"rating\", \"timestamp\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age: Normalize age to values between 0-1\n",
    "min_age = min(user_data[\"age\"])\n",
    "max_age = max(user_data[\"age\"])\n",
    "user_data['age'] = user_data[\"age\"].apply(lambda x: (x - min_age) / (max_age - min_age))\n",
    "\n",
    "\n",
    "# Rating: Normalize rating to values between 0-1\n",
    "# For training and test set\n",
    "min_rating = min(rating_data[\"rating\"])\n",
    "max_rating = max(rating_data[\"rating\"])\n",
    "\n",
    "training[\"rating\"] = training[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating))\n",
    "test[\"rating\"] = test[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating))\n",
    "\n",
    "\n",
    "# Timestamp: Normalize timestamps to values between 0-1\n",
    "# For training and test set\n",
    "min_time = min(rating_data[\"timestamp\"])\n",
    "max_time = max(rating_data[\"timestamp\"])\n",
    "\n",
    "training[\"timestamp\"] = training[\"timestamp\"].apply(lambda x: (x - min_time) / (max_time - min_time))\n",
    "test[\"timestamp\"] = test[\"timestamp\"].apply(lambda x: (x - min_time) / (max_time - min_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bring all the data together\n",
    "training = pd.merge(training, user_data, how='left', on='userID')\n",
    "test = pd.merge(test, user_data, how='left', on='userID')\n",
    "\n",
    "training = pd.merge(training, movie_data, how='left', on='movieID')\n",
    "test = pd.merge(test, movie_data, how='left', on='movieID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shift UserID and MovieID: Values starting from 0 instead of 1\n",
    "training[\"userID\"] = training[\"userID\"].apply(lambda x: x-1)\n",
    "training[\"movieID\"] = training[\"movieID\"].apply(lambda x: x-1)\n",
    "\n",
    "test[\"userID\"] = test[\"userID\"].apply(lambda x: x-1)\n",
    "test[\"movieID\"] = test[\"movieID\"].apply(lambda x: x-1)\n",
    "\n",
    "rating_data[\"userID\"] = rating_data[\"userID\"].apply(lambda x: x-1)\n",
    "rating_data[\"movieID\"] = rating_data[\"movieID\"].apply(lambda x: x-1)\n",
    "\n",
    "movie_data[\"movieID\"] = movie_data[\"movieID\"].apply(lambda x: x-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different Training and test sets for different models with different amount of information\n",
    "\n",
    "training_base = training[['userID', \"movieID\", \"rating\"]]\n",
    "test_base = test[['userID', \"movieID\", \"rating\"]]\n",
    "\n",
    "\n",
    "extended_columns = ['userID', 'movieID', 'rating', 'age', 'gender', 'unknown',\n",
    "       'Action', 'Adventure', 'Animation', \"Children's\", 'Comedy', 'Crime',\n",
    "       'Documentary', 'Drama', 'Fantasy', 'Film-Noir', 'Horror', 'Musical',\n",
    "       'Mystery', 'Romance', 'Sci-Fi', 'Thriller', 'War', 'Western']\n",
    "\n",
    "training_extended = training[extended_columns]\n",
    "test_extended = test[extended_columns]\n",
    "\n",
    "training_full = training\n",
    "test_full = test"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training and Validation Set\n",
    "\n",
    "I thoght of different ways to split the data.\n",
    "\n",
    "1. Split with user distribution\n",
    "\n",
    "    The users are split that there is a similar age and gender distribution in the training and test set. \n",
    "\n",
    "2. Split by movies/ratings from same user\n",
    "\n",
    "    Traings and test set both contain ratings from the same users. But in test set the are ratings not seen during training. It's the more common way to split data for recommenders. This method is also used by the pre-build \"u*.base\" and \"u*.test\" files. They contain at least one rating from each user.\n",
    "\n",
    "First I don't want to focus to much on data spliting because I want to get a model to run. That's why I startet with using the pre-builded sets.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_trining_test_set(training, test):\n",
    "    x_training = training.drop(columns=[\"rating\"])\n",
    "    x_training = x_training.to_numpy(dtype=np.float64)\n",
    "    y_training = training[\"rating\"].to_numpy(dtype=np.float64)\n",
    "\n",
    "    x_test = test.drop(columns=[\"rating\"])\n",
    "    x_test = x_test.to_numpy(dtype=np.float64)\n",
    "    y_test = test[\"rating\"].to_numpy(dtype=np.float64)\n",
    "\n",
    "    return x_training, y_training, x_test, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_training_base, y_training_base, x_test_base, y_test_base = convert_trining_test_set(training_base, test_base)\n",
    "training_compare, test_compare = training_extended.copy(), test_extended.copy()\n",
    "training_compare[\"userID\"], test_compare[\"userID\"] = 0, 0\n",
    "x_training_compare, y_training_compare, x_test_compare, y_test_compare = convert_trining_test_set(training_compare, test_compare)\n",
    "x_training_extended, y_training_extended, x_test_extended, y_test_extended = convert_trining_test_set(training_extended, test_extended)\n",
    "x_training_full, y_training_full, x_test_full, y_test_full = convert_trining_test_set(training_full, test_full)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build Model\n",
    "Code from \"Cold start\": https://keras.io/examples/structured_data/collaborative_filtering_movielens/#collaborative-filtering-for-movie-recommendations\n",
    "\n",
    "It uses collaborative filtering for recommendations. The figure shows how that works.\n",
    "\n",
    "<center><img src=\"graphics/2Dmatrix.png\" width=\"700\"><br></center>\n",
    "<center> Fig. 1: Collaborative Filtering. Image from https://developers.google.com/machine-learning/recommendation/collaborative/basics </center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EMBEDDING_SIZE = 50\n",
    "\n",
    "\n",
    "class RecommenderNet(keras.Model):\n",
    "    def __init__(self, num_users, num_movies, embedding_size, **kwargs):\n",
    "        super(RecommenderNet, self).__init__(**kwargs)\n",
    "        self.num_users = num_users\n",
    "        self.num_movies = num_movies\n",
    "        self.embedding_size = embedding_size\n",
    "        self.user_embedding = layers.Embedding(\n",
    "            num_users,\n",
    "            embedding_size,\n",
    "            embeddings_initializer=\"zeros\",\n",
    "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
    "        )\n",
    "        self.user_bias = layers.Embedding(num_users, 1)\n",
    "        self.movie_embedding = layers.Embedding(\n",
    "            num_movies,\n",
    "            embedding_size,\n",
    "            embeddings_initializer=\"zeros\",\n",
    "            embeddings_regularizer=keras.regularizers.l2(1e-6),\n",
    "        )\n",
    "        self.movie_bias = layers.Embedding(num_movies, 1)\n",
    "\n",
    "    def call(self, inputs):\n",
    "        user_vector = self.user_embedding(inputs[:, 0])\n",
    "        user_bias = self.user_bias(inputs[:, 0])\n",
    "        movie_vector = self.movie_embedding(inputs[:, 1])\n",
    "        movie_bias = self.movie_bias(inputs[:, 1])\n",
    "        dot_user_movie = tf.tensordot(user_vector, movie_vector, 2)\n",
    "        # Add all the components (including bias)\n",
    "        x = dot_user_movie + user_bias + movie_bias\n",
    "        # The sigmoid activation forces the rating to between 0 and 1\n",
    "        return tf.nn.sigmoid(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_base = RecommenderNet(len(user_data), len(movie_data), EMBEDDING_SIZE)\n",
    "model_extended = RecommenderNet(len(user_data), len(movie_data), EMBEDDING_SIZE)\n",
    "model_full = RecommenderNet(len(user_data), len(movie_data), EMBEDDING_SIZE)\n",
    "\n",
    "\n",
    "model_base.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_extended.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "model_full.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit Model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Callbacks for example early stopping prevent overfitting. It stops when theres no improvement in validation loss. Before early stopping the learning rate gets reduced so maybe the performance can achive a better result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = tf.keras.callbacks.EarlyStopping(\n",
    "                    monitor='val_loss',\n",
    "                    min_delta=0,\n",
    "                    patience=3,\n",
    "                    mode='auto'\n",
    "                    )\n",
    "\n",
    "reduce_lrs = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.25, patience=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_base = model_base.fit(\n",
    "    x=x_training_base,\n",
    "    y=y_training_base,\n",
    "    batch_size=16,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    callbacks = [es, reduce_lrs],\n",
    "    validation_data=(x_test_base, y_test_base),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_extended = model_extended.fit(\n",
    "    x=x_training_extended,\n",
    "    y=y_training_extended,\n",
    "    batch_size=16,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    callbacks = [es, reduce_lrs],\n",
    "    validation_data=(x_test_extended, y_test_extended),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history_full = model_full.fit(\n",
    "    x=x_training_full,\n",
    "    y=y_training_full,\n",
    "    batch_size=16,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    callbacks = [es, reduce_lrs],\n",
    "    validation_data=(x_test_full, y_test_full),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_base.history[\"loss\"], label=\"Base Train\")\n",
    "plt.plot(history_base.history[\"val_loss\"], label=\"Base Val\")\n",
    "plt.plot(history_extended.history[\"loss\"], label=\"Extended Train\")\n",
    "plt.plot(history_extended.history[\"val_loss\"], label=\"Extended Val\")\n",
    "plt.title(\"model loss\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_base.history[\"loss\"], label=\"Base Train\")\n",
    "plt.plot(history_base.history[\"val_loss\"], label=\"Base Val\")\n",
    "plt.plot(history_full.history[\"loss\"], label=\"Full Train\")\n",
    "plt.plot(history_full.history[\"val_loss\"], label=\"Full Val\")\n",
    "plt.title(\"model loss\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see: All models got the same loss and val_loss. There are no real differences between them in performance. A bit strange isn't it? That'S not what I expected when I started with this task. But more about that in my docu. ;)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Make Recommendations for users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_recommendations(model, userID):\n",
    "    movies_watched_by_user = rating_data[rating_data.userID == userID]\n",
    "    movies_not_watched = movie_data[\n",
    "        ~movie_data[\"movieID\"].isin(movies_watched_by_user.movieID.values)\n",
    "    ][\"movieID\"]\n",
    "    movies_not_watched = [[x] for x in movies_not_watched]\n",
    "    user_array = [[userID]] * len(movies_not_watched)\n",
    "    user_movie_array = np.hstack(\n",
    "        (user_array, movies_not_watched)\n",
    "    )\n",
    "    predicted_ratings = model.predict(user_movie_array).flatten()\n",
    "    top_ratings_indices = predicted_ratings.argsort()[-10:][::-1]\n",
    "    recommended_movies = movies[movies[\"movieID\"].isin(top_ratings_indices)][\"title\"].to_numpy()\n",
    "    return recommended_movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let us get a user and see the top recommendations.\n",
    "userID = 942\n",
    "recommended_movies_base = get_movie_recommendations(model_base, userID)\n",
    "recommended_movies_extended = get_movie_recommendations(model_extended, userID)\n",
    "recommended_movies_full = get_movie_recommendations(model_full, userID)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Showing recommendations for user: {}\".format(userID))\n",
    "print(\"====\" * 8)\n",
    "print(\"Movies with high ratings from user\")\n",
    "print(\"----\" * 8)\n",
    "movies_watched_by_user = rating_data[rating_data.userID == userID]\n",
    "top_movies_user = (\n",
    "    movies_watched_by_user.sort_values(by=\"rating\", ascending=False)\n",
    "    .head(5)\n",
    "    .movieID.values\n",
    ")\n",
    "movie_df_rows = movies[movies[\"movieID\"].isin(top_movies_user)]\n",
    "for row in movie_df_rows.itertuples():\n",
    "    print(row.title)\n",
    "\n",
    "print(\"----\" * 8)\n",
    "print(\"Top 10 movie recommendations\")\n",
    "print(\"----\" * 8)\n",
    "table_data = []\n",
    "for i in range(10):\n",
    "    table_data.append([recommended_movies_base[i], recommended_movies_extended[i],  recommended_movies_full[i]]) \n",
    "print(tabulate(table_data, headers=['Base Model', 'Extended Model', \"Full Model\"], tablefmt='orgtbl'))\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The movie recommendations are quite simular / completly the same for this user. Maybe the order is a bit different but the movies are the same. As all models got the same val_loss this is the expected result."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Predict and compare seen movies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_seen_movies(models: list, userID, n_movies = 5):\n",
    "    df = rating_data[rating_data[\"userID\"]==(userID+1)].head(n_movies)\n",
    "    movieIDs = df['movieID'].to_numpy()\n",
    "    movie_titles = []\n",
    "    movie_df_rows = movies[movies[\"movieID\"].isin(movieIDs)]\n",
    "    for row in movie_df_rows.itertuples():\n",
    "        movie_titles.append(row.title)\n",
    "    user_ratings = df['rating'].to_numpy()\n",
    "    model_predictions = []\n",
    "    user_movie_array = np.hstack(\n",
    "        ([[userID]] * n_movies, [[x] for x in movieIDs])\n",
    "    )\n",
    "    for model in models:\n",
    "        model_predictions.append(model.predict(user_movie_array).flatten()*5)\n",
    "\n",
    "    \n",
    "    return movie_titles, user_ratings, model_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userID = 457\n",
    "n_movies = 5\n",
    "movie_titles, user_ratings, model_predictions = predict_seen_movies([model_base, model_extended, model_full], userID, n_movies)\n",
    "print(\"Showing Predicitions for user: {}\".format(userID))\n",
    "print(\"====\" * 8)\n",
    "table_data = []\n",
    "for i in range(n_movies):\n",
    "    table_data.append([movie_titles[i], user_ratings[i],  model_predictions[0][i], model_predictions[1][i], model_predictions[2][i]]) \n",
    "print(tabulate(table_data, headers=['Movie Title', 'User Rating', 'Base Model', \"Extended Model\", \"Full Model\"], tablefmt='orgtbl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also the predictions for movies the user has already seen are all quite simular."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Compare Model\n",
    "Let's look how a model performes with just the demographic data without the userID. How much information is there? Or is evene more information in just the userID as a number that represents a individuum/person. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_compare = RecommenderNet(1, len(movie_data), EMBEDDING_SIZE)\n",
    "\n",
    "model_compare.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history_compare = model_compare.fit(\n",
    "    x=x_training_compare,\n",
    "    y=y_training_compare,\n",
    "    batch_size=16,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    callbacks = [es, reduce_lrs],\n",
    "    validation_data=(x_test_compare, y_test_compare),\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The validation loss is a higher then in the model with just the user ID. That means theres more information in the user ID then in the rest of the data. This explains why my model with more data is only slightly better."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Different Ideas for Training / Test Data\n",
    "In the models above I used the prebuild Training and Test Set splits. Now I want to try out to split the data on my own and compare the results. Also I want to use Cross Validation with the prebuild sets.\n",
    "#### Cross Validation\n",
    "Cross Validation is common way to use the data for Training and Validation when theres no real Training and Validation Test split. The figure below shows the concept of Cross Validation.\n",
    "<center><img src=\"graphics/cross_val.jpg\" width=\"700\"><br></center>\n",
    "<center> Fig. 2: Concept of Cross Validation. Image from https://de.mathworks.com/discovery/cross-validation.html </center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and preprocess the data sets\n",
    "training_cross = []\n",
    "test_cross = []\n",
    "for i in range(1, 6):\n",
    "    training = pd.read_csv('Data/ml-100k/u' + str(i) + '.base', sep='\\t', names=[\"userID\", \"movieID\", \"rating\", \"timestamp\"])\n",
    "    test = pd.read_csv('Data/ml-100k/u' + str(i) + '.test', sep='\\t', names=[\"userID\", \"movieID\", \"rating\", \"timestamp\"])\n",
    "\n",
    "    training[\"rating\"] = training[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating))\n",
    "    test[\"rating\"] = test[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating))\n",
    "\n",
    "    training[\"timestamp\"] = training[\"timestamp\"].apply(lambda x: (x - min_time) / (max_time - min_time))\n",
    "    test[\"timestamp\"] = test[\"timestamp\"].apply(lambda x: (x - min_time) / (max_time - min_time))\n",
    "\n",
    "    training = pd.merge(training, user_data, how='left', on='userID')\n",
    "    test = pd.merge(test, user_data, how='left', on='userID')\n",
    "\n",
    "    training = pd.merge(training, movie_data, how='left', on='movieID')\n",
    "    test = pd.merge(test, movie_data, how='left', on='movieID')\n",
    "\n",
    "    training[\"userID\"] = training[\"userID\"].apply(lambda x: x-1)\n",
    "    training[\"movieID\"] = training[\"movieID\"].apply(lambda x: x-1)\n",
    "\n",
    "    test[\"userID\"] = test[\"userID\"].apply(lambda x: x-1)\n",
    "    test[\"movieID\"] = test[\"movieID\"].apply(lambda x: x-1)\n",
    "\n",
    "    training = training[extended_columns]\n",
    "    test = test[extended_columns]  \n",
    "\n",
    "    training_cross.append(training)\n",
    "    test_cross.append(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Model\n",
    "model_cross = RecommenderNet(len(user_data), len(movie_data), EMBEDDING_SIZE)\n",
    "\n",
    "model_cross.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train Model using Cross Validation\n",
    "def cross_evaluate_model(training, test):\n",
    "\tscores, histories = list(), list()\n",
    "\tn_folds = 5 \n",
    "\t\n",
    "\t# enumerate splits\n",
    "\tfor i_fold in range(n_folds):\n",
    "\t\tprint(\"=\"*80)\n",
    "\t\tprint(\"Fold-{}\".format(i_fold + 1))\n",
    "\t\tprint(\"-\"*80)\n",
    "\t\tprint(\"Training & Validation\")\n",
    "\t\t\n",
    "\t\t# set train and test\n",
    "\t\tx_training = training[i_fold].drop(columns=[\"rating\"])\n",
    "\t\tx_training = x_training.to_numpy(dtype=np.float64)\n",
    "\t\ty_training = training[i_fold][\"rating\"].to_numpy(dtype=np.float64)\n",
    "\n",
    "\t\tx_test = test[i_fold].drop(columns=[\"rating\"])\n",
    "\t\tx_test = x_test.to_numpy(dtype=np.float64)\n",
    "\t\ty_test = test[i_fold][\"rating\"].to_numpy(dtype=np.float64)\n",
    "\n",
    "\t\t# fit model\n",
    "\t\thistory = model_cross.fit(x_training, y_training, epochs=5, batch_size=16, validation_data=(x_test, y_test), callbacks=[es])\n",
    "\t\t# evaluate model\n",
    "\t\tprint(\"-\"*80)\n",
    "\t\tprint(\"Testing/evaluation\")\n",
    "\t\tacc = model_cross.evaluate(x_test, y_test)\n",
    "\t\t# stores scores\n",
    "\t\tscores.append(acc)\n",
    "\t\thistories.append(history)\n",
    "\treturn scores, histories\n",
    "\n",
    "scores, histories = cross_evaluate_model(training_cross, test_cross)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluation of Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userID = 852\n",
    "recommended_movies_extended = get_movie_recommendations(model_extended, userID)\n",
    "recommended_movies_cross = get_movie_recommendations(model_cross, userID)\n",
    "print(\"Showing recommendations for user: {}\".format(userID))\n",
    "print(\"====\" * 8)\n",
    "print(\"Movies with high ratings from user\")\n",
    "print(\"----\" * 8)\n",
    "movies_watched_by_user = rating_data[rating_data.userID == userID]\n",
    "top_movies_user = (\n",
    "    movies_watched_by_user.sort_values(by=\"rating\", ascending=False)\n",
    "    .head(5)\n",
    "    .movieID.values\n",
    ")\n",
    "movie_df_rows = movies[movies[\"movieID\"].isin(top_movies_user)]\n",
    "for row in movie_df_rows.itertuples():\n",
    "    print(row.title)\n",
    "\n",
    "print(\"----\" * 8)\n",
    "print(\"Top 10 movie recommendations\")\n",
    "print(\"----\" * 8)\n",
    "table_data = []\n",
    "for i in range(10):\n",
    "    table_data.append([recommended_movies_extended[i], recommended_movies_cross[i]]) \n",
    "print(tabulate(table_data, headers=['Extended Model', \"Cross Model\"], tablefmt='orgtbl'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, this time there are completly different predictions. So which one is better? According to val_loss the extended model performeces better but let's have a look at some examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userID = 576\n",
    "n_movies = 5\n",
    "movie_titles, user_ratings, model_predictions = predict_seen_movies([model_extended, model_cross], userID, n_movies)\n",
    "print(\"Showing Predicitions for user: {}\".format(userID))\n",
    "print(\"====\" * 8)\n",
    "table_data = []\n",
    "for i in range(n_movies):\n",
    "    table_data.append([movie_titles[i], user_ratings[i],  model_predictions[0][i], model_predictions[1][i]]) \n",
    "print(tabulate(table_data, headers=['Movie Title', 'User Rating', \"Extended Model\", \"Cross Model\"], tablefmt='orgtbl'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, the values are close together. In generall the model without cross validation is a little closer to the User rating."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Own Data Split?\n",
    "Now it's time to compare my own data split to the prebuild one. But first I have to split the data. As always in this project I will use the whole data for Training and Validation and don't use a extra Test Set.\n",
    "The MovieLens data only contains data from users that minimum rated 20 movies. To guarantee there is a ranking from every user in the validation set I take the last 5 rated movies and put them into the validation set. This concept is often used for Recommender Systems. The figure below shows that for the last reviewed movie.\n",
    "\n",
    "<center><img src=\"graphics/data_split.png\" width=\"700\"><br></center>\n",
    "<center> Fig. 3: Data Spliting. Image from https://www.kaggle.com/code/jamesloy/deep-learning-based-recommender-systems/notebook </center>\n",
    "\n",
    "Now I want an 80:20 split of the data. So I fill the validation set with random ratings. But I pay attention to the gender distrubtion, so I fill with more Males then Females. Same could be done with age groups and their distribution. For now I just used genders."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_data = pd.read_csv('Data/ml-100k/u.data', sep='\\t', names=[\"userID\", \"movieID\", \"rating\", \"timestamp\"])\n",
    "\n",
    "df = pd.merge(rating_data, user_data, how='left', on='userID')\n",
    "\n",
    "df = pd.merge(df, movie_data, how='left', on='movieID')\n",
    "\n",
    "df[\"rating\"] = df[\"rating\"].apply(lambda x: (x - min_rating) / (max_rating - min_rating))\n",
    "df[\"userID\"] = df[\"userID\"].apply(lambda x: x-1)\n",
    "df[\"movieID\"] = df[\"movieID\"].apply(lambda x: x-1)\n",
    "\n",
    "df['rank_latest'] = df.groupby(['userID'])['timestamp'].rank(method='first', ascending=False)\n",
    "\n",
    "train_ratings = df[df['rank_latest'] >5]\n",
    "test_ratings = df[df['rank_latest'] <=5]\n",
    "\n",
    "print(\"Train : Test =\", len(train_ratings), \":\", len(test_ratings))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split genders\n",
    "train_ratings_male = train_ratings[train_ratings['gender'] == 1]\n",
    "train_ratings_female = train_ratings[train_ratings['gender'] == 0]\n",
    "\n",
    "# Fill test set to 80:20 split\n",
    "train_male, test_male = train_test_split(train_ratings_male, test_size=0.259*len(train_ratings_male)/len(train_ratings))\n",
    "train_female, test_female = train_test_split(train_ratings_female, test_size=0.259*len(train_ratings_female)/len(train_ratings))\n",
    "\n",
    "train_ratings = pd.concat([train_male, train_female], ignore_index=True)\n",
    "test_ratings = pd.concat([test_ratings, test_male, test_female], ignore_index=True)\n",
    "\n",
    "print(\"Train : Test =\", len(train_ratings), \":\", len(test_ratings))\n",
    "\n",
    "# drop columns that we no longer need\n",
    "train_ratings = train_ratings[extended_columns]\n",
    "test_ratings = test_ratings[extended_columns]\n",
    "\n",
    "x_training, y_training, x_test, y_test = convert_trining_test_set(train_ratings, test_ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define and Train model\n",
    "model_own_data = RecommenderNet(len(user_data), len(movie_data), EMBEDDING_SIZE)\n",
    "\n",
    "model_own_data.compile(\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    optimizer=keras.optimizers.Adam(learning_rate=0.001),\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "history_own_data = model_own_data.fit(\n",
    "    x=x_training,\n",
    "    y=y_training,\n",
    "    batch_size=16,\n",
    "    epochs=10,\n",
    "    verbose=1,\n",
    "    callbacks = [es, reduce_lrs],\n",
    "    validation_data=(x_test, y_test),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_extended.history[\"loss\"], label=\"Extended Train\")\n",
    "plt.plot(history_extended.history[\"val_loss\"], label=\"Extended Val\")\n",
    "plt.plot(history_own_data.history[\"loss\"], label=\"Own Train\")\n",
    "plt.plot(history_own_data.history[\"val_loss\"], label=\"Own Val\")\n",
    "plt.title(\"model loss\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend(loc=\"upper right\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The val_loss of the own data split looks like overfitting. Maybe the learning rate could be a bit smaller for a better result. In general the model with the prebuild data split performances much better."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userID = 27\n",
    "recommended_movies_extended = get_movie_recommendations(model_extended, userID)\n",
    "recommended_movies_own = get_movie_recommendations(model_own_data, userID)\n",
    "print(\"Showing recommendations for user: {}\".format(userID))\n",
    "print(\"====\" * 8)\n",
    "print(\"Movies with high ratings from user\")\n",
    "print(\"----\" * 8)\n",
    "movies_watched_by_user = rating_data[rating_data.userID == userID]\n",
    "top_movies_user = (\n",
    "    movies_watched_by_user.sort_values(by=\"rating\", ascending=False)\n",
    "    .head(5)\n",
    "    .movieID.values\n",
    ")\n",
    "movie_df_rows = movies[movies[\"movieID\"].isin(top_movies_user)]\n",
    "for row in movie_df_rows.itertuples():\n",
    "    print(row.title)\n",
    "\n",
    "print(\"----\" * 8)\n",
    "print(\"Top 10 movie recommendations\")\n",
    "print(\"----\" * 8)\n",
    "table_data = []\n",
    "for i in range(10):\n",
    "    table_data.append([recommended_movies_extended[i], recommended_movies_own[i]]) \n",
    "print(tabulate(table_data, headers=['Reference: Prebuild', \"Own Data Split\"], tablefmt='orgtbl'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some predictions are same, some are different. How do they perfom on seen movies?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "userID = 789\n",
    "n_movies = 5\n",
    "movie_titles, user_ratings, model_predictions = predict_seen_movies([model_extended, model_own_data], userID, n_movies)\n",
    "print(\"Showing Predicitions for user: {}\".format(userID))\n",
    "print(\"====\" * 8)\n",
    "table_data = []\n",
    "for i in range(n_movies):\n",
    "    table_data.append([movie_titles[i], user_ratings[i],  model_predictions[0][i], model_predictions[1][i]]) \n",
    "print(tabulate(table_data, headers=['Movie Title', 'User Rating', 'Reference: Prebuild', \"Own Data Split\"], tablefmt='orgtbl'))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some differences for the prediction for the movies the user has already reviewed. The results are slightly better for the Model with the pre-build datasets.\n",
    "That confirms the smaller val_loss value."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Different Model Idea: User - Ratings - Network\n",
    "Antoher way I wanted to try out the data is to train a network to predict a user activity with demographic data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rating_data = pd.read_csv('Data/ml-100k/u.data', sep='\\t', names=[\"userID\", \"movieID\", \"rating\", \"timestamp\"])\n",
    "\n",
    "max_given_ratings = rating_data[\"userID\"].value_counts().max()\n",
    "mean_given_ratings = rating_data[\"userID\"].value_counts().mean()\n",
    "given_ratings = rating_data[\"userID\"].value_counts()\n",
    "given_ratings.sort_index(inplace=True)\n",
    "\n",
    "user_data = pd.read_csv('Data/ml-100k/u.user', sep='|', names=[\"userID\", \"age\", \"gender\",  \"occupation\", \"zip code\"])\n",
    "user_data = user_data.drop(columns=['userID', 'zip code'])\n",
    "\n",
    "df, df['Activity'] = user_data.copy(), given_ratings.to_numpy()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some Data Analysis\n",
    "Now I will create some plots that will show the user activity in relation with their democraphic. User activity is defined as given ratings. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender Activity \n",
    "gender_activity = [df[df[\"gender\"]=='M']['Activity'].mean(), df[df[\"gender\"]=='F']['Activity'].mean()]\n",
    "plt.bar(['Male', \"Female\"], gender_activity)\n",
    "plt.xlabel(\"Genders\")\n",
    "plt.ylabel(\"Average given Ratings\")\n",
    "plt.title(\"User Activity - Genders\")\n",
    "plt.show() \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Occupation Activity\n",
    "occupation_activity = []\n",
    "for occupation in occupation_list.keys():\n",
    "    occupation_activity.append(df[df[\"occupation\"]==occupation]['Activity'].mean())\n",
    "plt.barh(list(occupation_list.keys()), occupation_activity)\n",
    "plt.ylabel(\"Occupation\")\n",
    "plt.xlabel(\"Average given Ratings\")\n",
    "plt.title(\"User Activity - Occupations\")\n",
    "plt.show() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Age Activity\n",
    "age_activity = []\n",
    "age_labels = [str(x) for x in age_counts.index]\n",
    "for x in age_counts.index:\n",
    "    age_activity.append(df[df.age.between(x.left, x.right)]['Activity'].mean())\n",
    "plt.bar(age_labels, age_activity)\n",
    "plt.xlabel(\"Age Group\")\n",
    "plt.ylabel(\"Average given Ratings\")\n",
    "plt.title(\"User Activity - Age\")\n",
    "plt.show() "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Males are slightly more active then Femals. The age has little impact on the user acitity. Younger people rate more movies. The biggest impact on the user activity has the occupation. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normalize age, gender and occupation to values between 0 and 1. This makes it easier to train."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gender: Convert 'M' and 'F' to 0 and 1\n",
    "user_data['gender'] = np.where(np.matrix(user_data['gender']) == 'M', 0, 1)[0]\n",
    "\n",
    "# Occupation\n",
    "occupation_list = {\"none\": 0,  \"other\": 1, \"student\": 2, \"homemaker\": 3, \"artist\": 4, \"writer\": 5, \"entertainment\": 6, \"administrator\": 7, \"educator\": 8, \"librarian\": 9,\n",
    "                   \"lawyer\": 10, \"healthcare\": 11, \"doctor\": 12, \"scientist\": 13, \"engineer\": 14, \"technician\": 15, \"programmer\": 16, \"marketing\": 17, \"salesman\": 18, \n",
    "                   \"executive\": 19, \"retired\": 20\n",
    "                }\n",
    "user_data['occupation'] = user_data['occupation'].map(occupation_list)\n",
    "user_data['occupation'] = user_data[\"occupation\"].apply(lambda x: x / 20)\n",
    "\n",
    "\n",
    "min_age = min(user_data[\"age\"])\n",
    "max_age = max(user_data[\"age\"])\n",
    "user_data['age'] = user_data[\"age\"].apply(lambda x: (x - min_age) / (max_age - min_age))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Split"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data split is nothing special. The data is in random order so it can get split in 80:20 for training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_indices = int(0.8 * user_data.shape[0])\n",
    "\n",
    "UA_x_train = user_data.to_numpy(dtype=np.float64)\n",
    "UA_y_train = given_ratings.to_numpy(dtype=np.float64)/max_given_ratings\n",
    "\n",
    "UA_x_train, UA_x_val, UA_y_train, UA_y_val = (\n",
    "    UA_x_train[:train_indices],\n",
    "    UA_x_train[train_indices:],\n",
    "    UA_y_train[:train_indices],\n",
    "    UA_y_train[train_indices:],\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define & Train Model "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code as start for this network: https://github.com/schutera/DeepDive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UA_model = tf.keras.models.Sequential([\n",
    "  tf.keras.layers.Flatten(),\n",
    "  tf.keras.layers.Dense(64, activation='relu'),\n",
    "  tf.keras.layers.Dense(16),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(8),\n",
    "  tf.keras.layers.Dense(1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = tf.keras.losses.MeanSquaredError()\n",
    "UA_model.compile(\n",
    "              optimizer=keras.optimizers.Adam(),\n",
    "              loss=loss_fn,\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UA_history = UA_model.fit(\n",
    "        UA_x_train,\n",
    "        UA_y_train,\n",
    "        epochs=5,\n",
    "        batch_size=4,\n",
    "        validation_data=(UA_x_val, UA_y_val),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(UA_history.history[\"loss\"])\n",
    "plt.plot(UA_history.history[\"val_loss\"])\n",
    "plt.title(\"model loss\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.xlabel(\"epoch\")\n",
    "plt.legend([\"train\", \"test\"], loc=\"upper left\")\n",
    "plt.show()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation and Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_user_activity_prediction(age: int, gender: int, occupation: str):\n",
    "    age = (age-min_age)/(max_age-min_age)\n",
    "    gender = np.clip(gender, 0, 1)\n",
    "    occupation = occupation_list[occupation]\n",
    "    occupation = np.clip(occupation/20, 0, 1)\n",
    "    prediction = UA_model.predict(x=[[age, gender, occupation]]).item(0)\n",
    "    prediction_absolute = int(prediction * max_given_ratings)\n",
    "    prediction_relative = prediction *max_given_ratings / mean_given_ratings\n",
    "    return prediction_absolute, prediction_relative\n",
    "\n",
    "def print_predicted_user_activity(age: int, gender: int, occupation: str):\n",
    "    print(\"----\"*8)\n",
    "    prediction_absolute, prediction_relative = get_user_activity_prediction(age, gender, occupation)\n",
    "    if gender == 0:\n",
    "        gender = 'Male'\n",
    "    else: gender = 'Female'\n",
    "    print(\"User: {} Years, {}, {}\".format(age, gender, occupation))\n",
    "    print(\"Predicted User Activity compared to Mean: {}\".format(prediction_relative))\n",
    "    print(\"Predicted given ratings: {}\".format(prediction_absolute))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now I want to try out same 'users':\n",
    "\n",
    "User 1:\n",
    "24 Years, Male, Student\n",
    "-> I would predict a high User Activity.\n",
    "\n",
    "User 2:\n",
    "24 Years, Female, Student\n",
    "-> My Prediciton: Less then User 1 because of Gender\n",
    "\n",
    "User 3:\n",
    "24 Years, Male, Artist\n",
    "-> My Prediciton: Less then User 1 because of Occupation\n",
    "\n",
    "User 4:\n",
    "55 Years, Female, Student\n",
    "-> My Prediciton: Less then User 2 because of Age\n",
    "\n",
    "User 5:\n",
    "30 Years, Male, Healthcare\n",
    "-> My Prediciton: Highest Score (because of occupation)\n",
    "\n",
    "User 6:\n",
    "80 Years, Female, Homemaker\n",
    "-> My Predicion: Lowest score\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print_predicted_user_activity(24, 0, \"student\")\n",
    "print_predicted_user_activity(24, 1, \"student\")\n",
    "print_predicted_user_activity(24, 1, \"artist\")\n",
    "print_predicted_user_activity(55, 1, \"student\")\n",
    "print_predicted_user_activity(30, 0, \"healthcare\")\n",
    "print_predicted_user_activity(80, 1, \"homemaker\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As predicted User 6 has the lowest score. The first 3 Users have a greater User Acitivtiy then the average.\n",
    "\n",
    "The other predicted outcomes did not arrive as expected."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## END :)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "324830d4e86a4d718d1d626d4695b4de13f4d5a52d42881a7e1f24422c94aec6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
